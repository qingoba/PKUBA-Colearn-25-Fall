package main

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"net/url"
	"time"
)

// ------------------------------------------------
// âš ï¸ å…³é”®é…ç½®ï¼šGraph API URL å’Œä»£ç†
// ------------------------------------------------

const (
	// âš ï¸ è¯·æ›¿æ¢ä¸ºä½ çš„ The Graph API URL
	// æ ¼å¼: https://gateway-arbitrum.network.thegraph.com/api/[YOUR_API_KEY]/subgraphs/id/[SUBGRAPH_ID]
	// è·å–æ–¹å¼: è®¿é—® https://thegraph.com/studio/ è·å– API Key
	GraphURL = "https://gateway-arbitrum.network.thegraph.com/api/YOUR_API_KEY/subgraphs/id/HUZDsRpEVP2AvzDCyzDHtdc64dyDxx8FQjzsmqSg4H3B"

	// âš ï¸ è¯·æ ¹æ®ä½ çš„ä»£ç†è½¯ä»¶ä¿®æ”¹ç«¯å£å·
	// å¸¸è§ä»£ç†ç«¯å£ï¼š
	//   - Clash: 7890 (HTTP), 7891 (SOCKS5)
	//   - V2Ray: 10808 (HTTP), 10809 (SOCKS5)
	//   - Shadowsocks: 1080 (SOCKS5)
	// å¦‚æœä¸éœ€è¦ä»£ç†ï¼Œå¯ä»¥è®¾ä¸ºç©ºå­—ç¬¦ä¸² ""
	PROXY_PORT = "YOUR_PROXY_PORT"

	// è®¾ç½®è¾ƒå¤§çš„è¶…æ—¶æ—¶é—´ï¼Œåº”å¯¹ä»£ç†è¿æ¥å»¶è¿Ÿ
	CONNECTION_TIMEOUT = 45 * time.Second

	// è°ƒè¯•æ¨¡å¼ï¼šæ‰“å°æŸ¥è¯¢å’Œå“åº”ï¼ˆç”¨äºæ’æŸ¥é—®é¢˜ï¼‰
	DEBUG_MODE = false

	// é‡è¯•é…ç½®
	MAX_RETRIES = 3              // æœ€å¤§é‡è¯•æ¬¡æ•°
	RETRY_DELAY = 2 * time.Second // é‡è¯•å»¶è¿Ÿ
)

// 1. å®šä¹‰æ•°æ®ç»“æ„ (æ ¹æ® GraphQL Schema)
// è¿™é‡Œçš„ç»“æ„å¿…é¡»ä¸ä½ çš„ Query è¿”å›ç»“æœä¸¥æ ¼ä¸€è‡´
type Response struct {
	Data struct {
		Pools []Pool `json:"pools"`
	} `json:"data"`
	Errors []struct {
		Message string `json:"message"`
	} `json:"errors,omitempty"` // GraphQL é”™è¯¯ä¿¡æ¯
}

type Pool struct {
	ID      string `json:"id"`
	Token0  struct {
		Symbol string `json:"symbol"`
	} `json:"token0"`
	Token1  struct {
		Symbol string `json:"symbol"`
	} `json:"token1"`
	FeeTier string `json:"feeTier"`
}

// æŸ¥è¯¢ç»“æœç»“æ„ï¼ˆç”¨äºé‡è¯•å‡½æ•°è¿”å›ï¼‰
type QueryResult struct {
	Pools  []Pool
	Errors []struct {
		Message string `json:"message"`
	}
}

func main() {
	log.Println("å¼€å§‹é…ç½®ä»£ç†å¹¶è¿æ¥åˆ° The Graph API")

	// 1. é…ç½®ä»£ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
	var transport *http.Transport
	if PROXY_PORT != "" && PROXY_PORT != "YOUR_PROXY_PORT" {
		proxyUrlString := fmt.Sprintf("http://127.0.0.1:%s", PROXY_PORT)
		proxyUrl, err := url.Parse(proxyUrlString)
		if err != nil {
			log.Fatalf("è§£æä»£ç† URL å¤±è´¥: %v", err)
		}
		transport = &http.Transport{
			Proxy: http.ProxyURL(proxyUrl),
		}
	} else {
		transport = &http.Transport{}
	}

	// 3. åˆ›å»ºè‡ªå®šä¹‰ HTTP å®¢æˆ·ç«¯ï¼Œè®¾ç½®è¶…æ—¶ï¼Œå¹¶ä½¿ç”¨ä»£ç†ä¼ è¾“å™¨
	client := &http.Client{
		Transport: transport,
		Timeout:   CONNECTION_TIMEOUT,
	}

	log.Println("âœ… ä»£ç†é…ç½®æˆåŠŸï¼Œå¼€å§‹è¿æ¥ The Graph API")

	// å…ˆåšä¸€ä¸ªæµ‹è¯•æŸ¥è¯¢ï¼ŒéªŒè¯ Subgraph æ˜¯å¦å¯ç”¨
	fmt.Println("ğŸ” æµ‹è¯•è¿æ¥...")
	testQuery := `
	{
		pools(first: 1) {
			id
		}
	}`
	
	reqBody, _ := json.Marshal(map[string]string{"query": testQuery})
	testResp, err := client.Post(GraphURL, "application/json", bytes.NewBuffer(reqBody))
	if err != nil {
		log.Fatalf("æµ‹è¯•è¿æ¥å¤±è´¥: %v", err)
	}
	defer testResp.Body.Close()
	
	testBody, _ := io.ReadAll(testResp.Body)
	var testResult Response
	if err := json.Unmarshal(testBody, &testResult); err != nil {
		log.Fatalf("æµ‹è¯•å“åº”è§£æå¤±è´¥: %v\nå“åº”: %s", err, string(testBody))
	}
	
	if len(testResult.Errors) > 0 {
		log.Printf("âš ï¸  æµ‹è¯•æŸ¥è¯¢å‘ç°é”™è¯¯:")
		for _, e := range testResult.Errors {
			log.Printf("  - %s", e.Message)
		}
		log.Fatalf("è¯·æ£€æŸ¥ Subgraph URL å’ŒæŸ¥è¯¢è¯­æ³•æ˜¯å¦æ­£ç¡®")
	}
	
	if len(testResult.Data.Pools) == 0 {
		log.Printf("âš ï¸  è­¦å‘Š: æµ‹è¯•æŸ¥è¯¢è¿”å› 0 æ¡æ•°æ®")
		log.Printf("å¯èƒ½çš„åŸå› :")
		log.Printf("  1. Subgraph ä¸­æ²¡æœ‰ pools æ•°æ®")
		log.Printf("  2. å®ä½“åç§°ä¸æ­£ç¡®ï¼ˆå¯èƒ½åº”è¯¥æ˜¯ pool è€Œä¸æ˜¯ poolsï¼‰")
		log.Printf("  3. éœ€è¦æ·»åŠ è¿‡æ»¤æ¡ä»¶")
		log.Printf("ç»§ç»­å°è¯•å®Œæ•´æŸ¥è¯¢...\n")
	} else {
		fmt.Printf("âœ… è¿æ¥æˆåŠŸï¼Œæ‰¾åˆ° %d ä¸ª Pool\n\n", len(testResult.Data.Pools))
	}

	// Cursor-based Pagination å®ç°
	lastID := "" // æ¸¸æ ‡åˆå§‹åŒ–ä¸ºç©ºï¼Œè¡¨ç¤ºä»ç¬¬ä¸€æ¡å¼€å§‹
	totalCount := 0
	requestCount := 0
	startTime := time.Now()

	fmt.Println("ğŸš€ å¼€å§‹ä½¿ç”¨ Cursor-based Pagination å…¨é‡æ‹‰å– Uniswap Pools...")
	fmt.Println("ğŸ’¡ æ ¸å¿ƒåŸç†ï¼šä½¿ç”¨ id_gt æ¡ä»¶ï¼Œåˆ©ç”¨æ•°æ®åº“ç´¢å¼•å®ç°é«˜æ•ˆåˆ†é¡µ\n")

	for {
		// æ„é€  GraphQL Query
		// æ ¸å¿ƒæŠ€å·§: 
		//   - ç¬¬ä¸€é¡µï¼šä¸è®¾ç½® where æ¡ä»¶ï¼ˆlastID ä¸ºç©ºï¼‰
		//   - åç»­é¡µï¼šä½¿ç”¨ where: { id_gt: lastID } è¿‡æ»¤
		//   - å¿…é¡»é…åˆ orderBy: id å’Œ orderDirection: asc ä½¿ç”¨
		var query string
		if lastID == "" {
			// ç¬¬ä¸€é¡µï¼šä¸éœ€è¦ where æ¡ä»¶
			query = `
			{
				pools(
					first: 1000,
					orderBy: id,
					orderDirection: asc
				) {
					id
					feeTier
					token0 { symbol }
					token1 { symbol }
				}
			}`
		} else {
			// åç»­é¡µï¼šä½¿ç”¨æ¸¸æ ‡è¿‡æ»¤
			query = fmt.Sprintf(`
			{
				pools(
					first: 1000,
					orderBy: id,
					orderDirection: asc,
					where: { id_gt: "%s" }
				) {
					id
					feeTier
					token0 { symbol }
					token1 { symbol }
				}
			}`, lastID)
		}

		// ä½¿ç”¨å¸¦é‡è¯•çš„æŸ¥è¯¢å‡½æ•°
		result, success := fetchWithRetry(client, query, requestCount+1)
		if !success {
			log.Fatalf("âŒ æŸ¥è¯¢å¤±è´¥ï¼Œå·²é‡è¯• %d æ¬¡", MAX_RETRIES)
		}
		requestCount++

		// å¤„ç†æ•°æ®ä¸é€€å‡ºæ¡ä»¶
		pools := result.Pools
		if len(pools) == 0 {
			fmt.Println("\nâœ… æ‹‰å–å®Œæˆï¼")
			break
		}

		// æ‰“å°æœ¬é¡µç¬¬ä¸€æ¡å’Œæœ€åä¸€æ¡ä½œä¸ºè¿›åº¦å±•ç¤º
		fmt.Printf("  [è¯·æ±‚ #%d] è·å– %d æ¡ | èŒƒå›´: %s ... %s\n",
			requestCount, len(pools), 
			pools[0].ID[:min(12, len(pools[0].ID))]+"...",
			pools[len(pools)-1].ID[:min(12, len(pools[len(pools)-1].ID))]+"...")

		totalCount += len(pools)

		// æ›´æ–°æ¸¸æ ‡ (å…³é”®æ­¥éª¤)
		// å°†æœ€åä¸€æ¡è®°å½•çš„ ID ä½œä¸ºä¸‹ä¸€æ¬¡æŸ¥è¯¢çš„èµ·ç‚¹
		lastID = pools[len(pools)-1].ID

		// ç¨å¾® sleep ä¸€ä¸‹ï¼Œé¿å…è§¦å‘ API Rate Limit
		time.Sleep(100 * time.Millisecond)
	}

	elapsed := time.Since(startTime)
	fmt.Printf("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:\n")
	fmt.Printf("  - æ€»è®¡è·å–: %d ä¸ª Pool\n", totalCount)
	fmt.Printf("  - è¯·æ±‚æ¬¡æ•°: %d æ¬¡\n", requestCount)
	fmt.Printf("  - æ€»è€—æ—¶: %v\n", elapsed)
	if requestCount > 0 {
		fmt.Printf("  - å¹³å‡è€—æ—¶: %v/è¯·æ±‚\n", elapsed/time.Duration(requestCount))
	}
	
	fmt.Println("\nğŸ’¡ ä¸ºä»€ä¹ˆ Cursor-based é«˜æ•ˆï¼Ÿ")
	fmt.Println("  - åˆ©ç”¨æ•°æ®åº“ä¸»é”®ç´¢å¼•ï¼Œç›´æ¥å®šä½åˆ°æ¸¸æ ‡ä½ç½®")
	fmt.Println("  - å¤æ‚åº¦: O(log N) æˆ– O(1)ï¼Œè€Œé O(N)")
	fmt.Println("  - ä¸å—æ•°æ®æ€»é‡å½±å“ï¼Œæ€§èƒ½ç¨³å®š")
}

// fetchWithRetry: å¸¦é‡è¯•æœºåˆ¶çš„æŸ¥è¯¢å‡½æ•°
// ä¸ºä»€ä¹ˆéœ€è¦é‡è¯•ï¼ŸThe Graph ä½¿ç”¨å»ä¸­å¿ƒåŒ–æ¶æ„ï¼Œå¤šä¸ªç´¢å¼•å™¨æä¾›æœåŠ¡
// å½“æŸ¥è¯¢å¤æ‚æˆ–æ•°æ®é‡å¤§æ—¶ï¼ŒæŸäº›ç´¢å¼•å™¨å¯èƒ½è¶…æ—¶æˆ–å¤±è´¥ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡
func fetchWithRetry(client *http.Client, query string, requestNum int) (*QueryResult, bool) {
	reqBody, _ := json.Marshal(map[string]string{"query": query})
	
	// è°ƒè¯•æ¨¡å¼ï¼šæ‰“å°æŸ¥è¯¢
	if DEBUG_MODE {
		fmt.Printf("\n[DEBUG] æŸ¥è¯¢å†…å®¹:\n%s\n", query)
	}
	
	for attempt := 1; attempt <= MAX_RETRIES; attempt++ {
		resp, err := client.Post(GraphURL, "application/json", bytes.NewBuffer(reqBody))
		if err != nil {
			if attempt < MAX_RETRIES {
				log.Printf("âš ï¸  è¯·æ±‚å¤±è´¥ (å°è¯• %d/%d): %vï¼Œ%v åé‡è¯•...", 
					attempt, MAX_RETRIES, err, RETRY_DELAY)
				time.Sleep(RETRY_DELAY)
				continue
			}
			return nil, false
		}

		// æ£€æŸ¥ HTTP çŠ¶æ€ç 
		if resp.StatusCode != http.StatusOK {
			body, _ := io.ReadAll(resp.Body)
			resp.Body.Close()
			if attempt < MAX_RETRIES {
				log.Printf("âš ï¸  HTTP é”™è¯¯ (å°è¯• %d/%d): çŠ¶æ€ç  %dï¼Œ%v åé‡è¯•...", 
					attempt, MAX_RETRIES, resp.StatusCode, RETRY_DELAY)
				time.Sleep(RETRY_DELAY)
				continue
			}
			log.Printf("âŒ HTTP é”™è¯¯: çŠ¶æ€ç  %d, å“åº”: %s", resp.StatusCode, string(body))
			return nil, false
		}

		// è§£æå“åº”
		body, _ := io.ReadAll(resp.Body)
		resp.Body.Close()
		
		// è°ƒè¯•æ¨¡å¼ï¼šæ‰“å°å“åº”
		if DEBUG_MODE {
			fmt.Printf("[DEBUG] å“åº”å†…å®¹ (å‰500å­—ç¬¦):\n%s...\n", string(body)[:min(500, len(string(body)))])
		}
		
		var result Response
		if err := json.Unmarshal(body, &result); err != nil {
			if attempt < MAX_RETRIES {
				log.Printf("âš ï¸  JSON è§£æå¤±è´¥ (å°è¯• %d/%d): %vï¼Œ%v åé‡è¯•...", 
					attempt, MAX_RETRIES, err, RETRY_DELAY)
				time.Sleep(RETRY_DELAY)
				continue
			}
			log.Printf("âŒ JSON è§£æé”™è¯¯: %v\nå“åº”å†…å®¹: %s", err, string(body))
			return nil, false
		}

		// æ£€æŸ¥ GraphQL é”™è¯¯
		if len(result.Errors) > 0 {
			// åˆ¤æ–­æ˜¯å¦ä¸ºå¯é‡è¯•çš„é”™è¯¯ï¼ˆå¦‚è¶…æ—¶ã€ç´¢å¼•å™¨é”™è¯¯ï¼‰
			isRetryable := false
			errorMsg := ""
			for _, e := range result.Errors {
				errorMsg += e.Message + "; "
				// æ£€æŸ¥æ˜¯å¦åŒ…å«è¶…æ—¶æˆ–ç´¢å¼•å™¨é”™è¯¯çš„å…³é”®è¯
				if containsAny(e.Message, []string{"timeout", "Timeout", "indexer", "bad indexers", "statement timeout"}) {
					isRetryable = true
				}
			}
			
			if isRetryable && attempt < MAX_RETRIES {
				log.Printf("âš ï¸  GraphQL é”™è¯¯ (è¯·æ±‚ #%d, å°è¯• %d/%d): %s", 
					requestNum, attempt, MAX_RETRIES, errorMsg)
				log.Printf("    ğŸ’¡ è¿™æ˜¯ The Graph å»ä¸­å¿ƒåŒ–æ¶æ„çš„æ­£å¸¸ç°è±¡ï¼Œæ­£åœ¨é‡è¯•...")
				time.Sleep(RETRY_DELAY)
				continue
			}
			
			// ä¸å¯é‡è¯•çš„é”™è¯¯æˆ–å·²é‡è¯•å¤šæ¬¡
			log.Printf("âš ï¸  GraphQL é”™è¯¯ (è¯·æ±‚ #%d):", requestNum)
			for _, e := range result.Errors {
				log.Printf("  - %s", e.Message)
			}
			
			// å¦‚æœæœ‰éƒ¨åˆ†æ•°æ®ï¼Œä»ç„¶è¿”å›
			if len(result.Data.Pools) > 0 {
				return &QueryResult{
					Pools:  result.Data.Pools,
					Errors: result.Errors,
				}, true
			}
			
			// æ— æ•°æ®ä¸”ä¸å¯é‡è¯•ï¼Œè¿”å›å¤±è´¥
			if attempt >= MAX_RETRIES {
				return nil, false
			}
		}

		// æˆåŠŸè¿”å›
		return &QueryResult{
			Pools:  result.Data.Pools,
			Errors: result.Errors,
		}, true
	}
	
	return nil, false
}

// containsAny: æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦åŒ…å«ä»»æ„ä¸€ä¸ªå…³é”®è¯
func containsAny(s string, keywords []string) bool {
	for _, keyword := range keywords {
		if len(s) >= len(keyword) {
			for i := 0; i <= len(s)-len(keyword); i++ {
				if s[i:i+len(keyword)] == keyword {
					return true
				}
			}
		}
	}
	return false
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

